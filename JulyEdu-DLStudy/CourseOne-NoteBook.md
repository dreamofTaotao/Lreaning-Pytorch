
# 第一课
 
## 1.本节课所讲知识点

### 1.1微积分——极限
1.1.1极限的基本概念（lim）
1.1.2无穷小阶数——函数的比较后无限趋近于0。
1.1.3微分学的核心思想是逼近，导数的概念是两值的极限《=》线性逼近
     注意导数的本质概念,y'=dy/dx。
     可以说微分就是求导数。
1.1.3.1 基本求导法则：
        <1>链式求导法则
        <2>加法法则
        <3>乘法法则
        <4>除法法则
        <5>反函数求导
          需要特别注意的是，所有求导法则都可以通过链式法则结合二元函数的偏导数推导出来。
1.1.4函数的高阶导数
导数对函数的线性逼近，高阶导数是对导数函数的继续线性逼近。
1.1.5多项式逼近方式描述高阶导数，就得到了泰勒级数。
1.1.6深度模型一般都是使用一阶导数，模型参数越多越容易犯错误。注意导数之间的相关
概念。

### 1.2积分学——无穷求和
1.2.1想要优化一个函数，那么需要对以往的所有损失值进行整体估计。
1.2.2牛顿莱布尼茨公式——微积分之间存在练习，积分通过求微分的原函数计算区间可到，基本的积分值。
1.2.3优化问题：
  1.2.3.1牛顿法
    全局极小值/局部极小值，这两者一定满足一阶（导数/梯度）为0。
    牛顿法确定极值的算法是对局部的函数找到极小值或者极大值，对局部的函数进行二阶导数可以得到该局部的函数的凹凸性从而确定当前区域中的局部极大值或局部
极小值。
    学习率过大容易跑太远，学习率如果较小容易陷入某一“陷阱”中。
  1.2.3.2梯度下降法
  
### 1.3随机变量与概率：概率密度函数的积分
1.3.1离散随机变量
  对于离散随机变量，概率就是概率函数的求和。
1.3.2连续随机变量
  对于连续型随机变量，概率就是概率密度函数的积分。
  不论是离散还是连续随机变量，概率函数和概率密度函数的定义域即为这个随机变量的置值域。
1.3.3事件的概率
  整个概率空间是一个事件，此事件一定发生所以全空间的概率为1。
1.3.4事件的条件概率
  某事件发生的情况下，另一个事件发生的概率P(A|B)=P(AB)/P(B)
1.3.5贝叶斯公式
  条件概率公式满足P(A|B)=(P(B|A)P(A))/P(B)=((P(AB)/P(A))P(A))/P(B)
1.3.6随机变量的矩（大数定律和中心极限定理）
  期望的问题，是大量的数据支撑的。
1.3.7参数估计问题
  1.3.7.1矩估计——大数定律
  1.3.7.2极大似然估计基本原理：最大化似然函数
  1.3.7.3正态分布的参数估计
1.3.8线性映射与矩阵
  1.3.8.1矩阵就是描述线性函数的集合
  1.3.8.2V和W是两个线性空间，V->W如果满足某种线性关系的话就是一种线性映射。
         线性映射的本质就是保持线性结构的映射
         到自身的线性映射上面的那种V-W就是线性变换
  1.3.8.3线性变换的矩阵描述
1.3.9相似变换
1.3.10相似不变形、相合变换*
  任何一个对称矩阵A都可以正交相似于一个对角矩阵D。
  总存在一个正交矩阵P，使得A=P的倒置 * DP
  主成分分析（PCA）主要的目的是降维，也可以起到分类的作用。
  举例：推荐系统
### 1.4凸优化优化
  1.4.1凸集合问题
  1.4.2凸函数定义
  
  
## 收获与体验

## 需要进一步学习掌握的
